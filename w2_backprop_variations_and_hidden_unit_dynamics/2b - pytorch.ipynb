{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PyTorch\n",
    "The following code fragments illustrate the typical structure of a PyTorch program, with further details and various options for each component.\n",
    "\n",
    "# Typical Structure of a PyTorch Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Defining a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # define structure of the network here\n",
    "\n",
    "    def forward(self, input):\n",
    "        # apply network and return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Defining a Custom Model\n",
    "This code defines a module for computing a function of the form $(x,y) \\mapsto Ax \\log(y) + B y^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.A = nn.Parameter(torch.randn((1),requires_grad=True))\n",
    "        self.B = nn.Parameter(torch.randn((1),requires_grad=True))\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.A * input[:,0] * torch.log(input[:,1]) \\\n",
    "               + self.B * input[:,1] * input[:,1]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create neural network according to model specification\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = MyModel().to(device) # CPU or GPU\n",
    "\n",
    "# prepare to load the training and test data\n",
    "train_loader = torch.utils.data.DataLoader(...)\n",
    "test_loader = torch.utils.data.DataLoader(...)\n",
    "\n",
    "# choose between SGD, Adam or other optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters,...)\n",
    "\n",
    "# enter the training loop\n",
    "for epoch in range(1, epochs):\n",
    "    train(params, net, device, train_loader, optimizer)\n",
    "    # periodically evaluate the network on the test data\n",
    "    if epoch % 10 == 0:\n",
    "        test(params, net, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Building a Net from Individual Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.in_to_hid = torch.nn.Linear(2,2)\n",
    "        self.hid_to_out = torch.nn.Linear(2,1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        hid_sum = self.in_to_hid(input)\n",
    "        hidden = torch.tanh(hid_sum)\n",
    "        out_sum = self.hid_to_out(hidden)\n",
    "        output = torch.sigmoid(out_sum)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Defining a Sequential Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_input, num_hid, num_out):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(num_input, num_hid),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hid, num_out),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sequential Components\n",
    "## Network Layers:\n",
    "- nn.Linear()\n",
    "- nn.Conv2d()\n",
    "\n",
    "## Intermediate Operators:\n",
    "- nn.Dropout()\n",
    "- nn.BatchNorm()\n",
    "\n",
    "## Activation Functions:\n",
    "- nn.Tanh()\n",
    "- nn.Sigmoid()\n",
    "- nn.ReLU()\n",
    "\n",
    "# Declaring Data Explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "# input and target values for the XOR task\n",
    "input = torch.Tensor([[0,0],[0,1],[1,0],[1,1]])\n",
    "target = torch.Tensor([[0],[1],[1],[0]])\n",
    "\n",
    "xdata = torch.utils.data.TensorDataset(input, target)\n",
    "train_loader = torch.utils.data.DataLoader(xdata, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loading Data from a .csv File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sonar.all-data.csv\")\n",
    "df = df.replace('R', 0)\n",
    "df = df.replace('M', 1)\n",
    "data = torch.tensor(df.values,dtype=torch.float32)\n",
    "num_input = data.shape[1] - 1\n",
    "input = data[:, 0:num_input]\n",
    "target = data[:, num_input:num_input + 1]\n",
    "dataset = torch.utils.data.TensorDataset(input,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Custom Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from data import ImageFolder\n",
    "\n",
    "# load images from a specified directory\n",
    "dataset = ImageFolder(folder, transform)\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "# download popular image datasets remotely\n",
    "mnistset = dsets.MNIST(...)\n",
    "cifarset = dsets.CIFAR10(...)\n",
    "celebset = dsets.CelebA(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Choosing an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SGD stands for “Stochastic Gradient Descent”\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=0.01,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0001\n",
    ")\n",
    "\n",
    "# Adam = Adaptive Moment Estimation (good for deep networks)\n",
    "optimizer = torch.optim.Adam(\n",
    "    net.parameters(),\n",
    "    eps=0.000001,\n",
    "    lr=0.01,\n",
    "    betas=(0.5,0.999),\n",
    "    weight_decay=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(args, net, device, train_loader, optimizer):\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad() # zero the gradients\n",
    "        output = net(data) # apply network\n",
    "        loss = ... # compute loss function\n",
    "        loss.backward() # update gradients\n",
    "        optimizer.step() # update weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "loss = torch.sum((output - target) * (output - target))\n",
    "loss = F.nll_loss(output, target)\n",
    "loss = F.binary_cross_entropy(output, target)\n",
    "loss = F.softmax(output, dim=1)\n",
    "loss = F.log_softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "with torch.no_grad(): # suppress updating of gradients\n",
    "    net.eval() # toggle batch norm, dropout\n",
    "    test_loss = 0\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        test_loss += ...\n",
    "    print(test_loss)\n",
    "    net.train() # toggle batch norm, dropout back again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Computational Graphs\n",
    "PyTorch automatically builds a computational graph, enabling it to backpropagate derivatives.\n",
    "\n",
    "Every parameter includes `.data` and `.grad` components, for example:\n",
    "`A.data`\n",
    "`A.grad`\n",
    "\n",
    "`optimizer.zero_grad()` sets all `.grad` components to zero.\n",
    "\n",
    "`loss.backward()` updates the `.grad` component of all Parameters by backpropagating gradients through the computational graph.\n",
    "\n",
    "`optimizer.step()` updates the `.data` components.\n",
    "\n",
    "## Controlling the Computational Graph\n",
    "If we need to stop the gradients from being backpropagated through a certain variable (or expression) A, we can exclude it from the computational graph by using:\n",
    "\n",
    "`A.detach()`\n",
    "\n",
    "By default, `loss.backward()` discards the computational graph after computing the gradients.\n",
    "\n",
    "If needed, we can force it to keep the computational graph by calling it this way:\n",
    "\n",
    "`loss.backward(retain_graph=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise: Running pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following program solves the simplest possible machine learning task:\n",
    "\n",
    "solve $f(x)=Axf(x)$ such that $f(1)=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep  1: zero_grad(): A.grad=  None  A.data= 0.0000 loss= 0.5000\n",
      "            step(): A.grad=-1.0000 A.data= 1.9000\n",
      "Ep  2: zero_grad(): A.grad= 0.0000 A.data= 1.9000 loss= 0.4050\n",
      "            step(): A.grad= 0.9000 A.data= 1.9000\n",
      "Ep  3: zero_grad(): A.grad= 0.0000 A.data= 1.9000 loss= 0.4050\n",
      "            step(): A.grad= 0.9000 A.data= 0.1900\n",
      "Ep  4: zero_grad(): A.grad= 0.0000 A.data= 0.1900 loss= 0.3280\n",
      "            step(): A.grad=-0.8100 A.data= 0.1900\n",
      "Ep  5: zero_grad(): A.grad= 0.0000 A.data= 0.1900 loss= 0.3280\n",
      "            step(): A.grad=-0.8100 A.data= 1.7290\n",
      "Ep  6: zero_grad(): A.grad= 0.0000 A.data= 1.7290 loss= 0.2657\n",
      "            step(): A.grad= 0.7290 A.data= 1.7290\n",
      "Ep  7: zero_grad(): A.grad= 0.0000 A.data= 1.7290 loss= 0.2657\n",
      "            step(): A.grad= 0.7290 A.data= 0.3439\n",
      "Ep  8: zero_grad(): A.grad= 0.0000 A.data= 0.3439 loss= 0.2152\n",
      "            step(): A.grad=-0.6561 A.data= 0.3439\n",
      "Ep  9: zero_grad(): A.grad= 0.0000 A.data= 0.3439 loss= 0.2152\n",
      "            step(): A.grad=-0.6561 A.data= 1.5905\n",
      "Ep 10: zero_grad(): A.grad= 0.0000 A.data= 1.5905 loss= 0.1743\n",
      "            step(): A.grad= 0.5905 A.data= 1.5905\n",
      "Ep 11: zero_grad(): A.grad= 0.0000 A.data= 1.5905 loss= 0.1743\n",
      "            step(): A.grad= 0.5905 A.data= 0.4686\n",
      "Ep 12: zero_grad(): A.grad= 0.0000 A.data= 0.4686 loss= 0.1412\n",
      "            step(): A.grad=-0.5314 A.data= 0.4686\n",
      "Ep 13: zero_grad(): A.grad= 0.0000 A.data= 0.4686 loss= 0.1412\n",
      "            step(): A.grad=-0.5314 A.data= 1.4783\n",
      "Ep 14: zero_grad(): A.grad= 0.0000 A.data= 1.4783 loss= 0.1144\n",
      "            step(): A.grad= 0.4783 A.data= 1.4783\n",
      "Ep 15: zero_grad(): A.grad= 0.0000 A.data= 1.4783 loss= 0.1144\n",
      "            step(): A.grad= 0.4783 A.data= 0.5695\n",
      "Ep 16: zero_grad(): A.grad= 0.0000 A.data= 0.5695 loss= 0.0927\n",
      "            step(): A.grad=-0.4305 A.data= 0.5695\n",
      "Ep 17: zero_grad(): A.grad= 0.0000 A.data= 0.5695 loss= 0.0927\n",
      "            step(): A.grad=-0.4305 A.data= 1.3874\n",
      "Ep 18: zero_grad(): A.grad= 0.0000 A.data= 1.3874 loss= 0.0750\n",
      "            step(): A.grad= 0.3874 A.data= 1.3874\n",
      "Ep 19: zero_grad(): A.grad= 0.0000 A.data= 1.3874 loss= 0.0750\n",
      "            step(): A.grad= 0.3874 A.data= 0.6513\n",
      "Ep 20: zero_grad(): A.grad= 0.0000 A.data= 0.6513 loss= 0.0608\n",
      "            step(): A.grad=-0.3487 A.data= 0.6513\n",
      "Ep 21: zero_grad(): A.grad= 0.0000 A.data= 0.6513 loss= 0.0608\n",
      "            step(): A.grad=-0.3487 A.data= 1.3138\n",
      "Ep 22: zero_grad(): A.grad= 0.0000 A.data= 1.3138 loss= 0.0492\n",
      "            step(): A.grad= 0.3138 A.data= 1.3138\n",
      "Ep 23: zero_grad(): A.grad= 0.0000 A.data= 1.3138 loss= 0.0492\n",
      "            step(): A.grad= 0.3138 A.data= 0.7176\n",
      "Ep 24: zero_grad(): A.grad= 0.0000 A.data= 0.7176 loss= 0.0399\n",
      "            step(): A.grad=-0.2824 A.data= 0.7176\n",
      "Ep 25: zero_grad(): A.grad= 0.0000 A.data= 0.7176 loss= 0.0399\n",
      "            step(): A.grad=-0.2824 A.data= 1.2542\n",
      "Ep 26: zero_grad(): A.grad= 0.0000 A.data= 1.2542 loss= 0.0323\n",
      "            step(): A.grad= 0.2542 A.data= 1.2542\n",
      "Ep 27: zero_grad(): A.grad= 0.0000 A.data= 1.2542 loss= 0.0323\n",
      "            step(): A.grad= 0.2542 A.data= 0.7712\n",
      "Ep 28: zero_grad(): A.grad= 0.0000 A.data= 0.7712 loss= 0.0262\n",
      "            step(): A.grad=-0.2288 A.data= 0.7712\n",
      "Ep 29: zero_grad(): A.grad= 0.0000 A.data= 0.7712 loss= 0.0262\n",
      "            step(): A.grad=-0.2288 A.data= 1.2059\n",
      "Ep 30: zero_grad(): A.grad= 0.0000 A.data= 1.2059 loss= 0.0212\n",
      "            step(): A.grad= 0.2059 A.data= 1.2059\n",
      "Ep 31: zero_grad(): A.grad= 0.0000 A.data= 1.2059 loss= 0.0212\n",
      "            step(): A.grad= 0.2059 A.data= 0.8147\n",
      "Ep 32: zero_grad(): A.grad= 0.0000 A.data= 0.8147 loss= 0.0172\n",
      "            step(): A.grad=-0.1853 A.data= 0.8147\n",
      "Ep 33: zero_grad(): A.grad= 0.0000 A.data= 0.8147 loss= 0.0172\n",
      "            step(): A.grad=-0.1853 A.data= 1.1668\n",
      "Ep 34: zero_grad(): A.grad= 0.0000 A.data= 1.1668 loss= 0.0139\n",
      "            step(): A.grad= 0.1668 A.data= 1.1668\n",
      "Ep 35: zero_grad(): A.grad= 0.0000 A.data= 1.1668 loss= 0.0139\n",
      "            step(): A.grad= 0.1668 A.data= 0.8499\n",
      "Ep 36: zero_grad(): A.grad= 0.0000 A.data= 0.8499 loss= 0.0113\n",
      "            step(): A.grad=-0.1501 A.data= 0.8499\n",
      "Ep 37: zero_grad(): A.grad= 0.0000 A.data= 0.8499 loss= 0.0113\n",
      "            step(): A.grad=-0.1501 A.data= 1.1351\n",
      "Ep 38: zero_grad(): A.grad= 0.0000 A.data= 1.1351 loss= 0.0091\n",
      "            step(): A.grad= 0.1351 A.data= 1.1351\n",
      "Ep 39: zero_grad(): A.grad= 0.0000 A.data= 1.1351 loss= 0.0091\n",
      "            step(): A.grad= 0.1351 A.data= 0.8784\n",
      "Ep 40: zero_grad(): A.grad= 0.0000 A.data= 0.8784 loss= 0.0074\n",
      "            step(): A.grad=-0.1216 A.data= 0.8784\n",
      "Ep 41: zero_grad(): A.grad= 0.0000 A.data= 0.8784 loss= 0.0074\n",
      "            step(): A.grad=-0.1216 A.data= 1.1094\n",
      "Ep 42: zero_grad(): A.grad= 0.0000 A.data= 1.1094 loss= 0.0060\n",
      "            step(): A.grad= 0.1094 A.data= 1.1094\n",
      "Ep 43: zero_grad(): A.grad= 0.0000 A.data= 1.1094 loss= 0.0060\n",
      "            step(): A.grad= 0.1094 A.data= 0.9015\n",
      "Ep 44: zero_grad(): A.grad= 0.0000 A.data= 0.9015 loss= 0.0048\n",
      "            step(): A.grad=-0.0985 A.data= 0.9015\n",
      "Ep 45: zero_grad(): A.grad= 0.0000 A.data= 0.9015 loss= 0.0048\n",
      "            step(): A.grad=-0.0985 A.data= 1.0886\n",
      "Ep 46: zero_grad(): A.grad= 0.0000 A.data= 1.0886 loss= 0.0039\n",
      "            step(): A.grad= 0.0886 A.data= 1.0886\n",
      "Ep 47: zero_grad(): A.grad= 0.0000 A.data= 1.0886 loss= 0.0039\n",
      "            step(): A.grad= 0.0886 A.data= 0.9202\n",
      "Ep 48: zero_grad(): A.grad= 0.0000 A.data= 0.9202 loss= 0.0032\n",
      "            step(): A.grad=-0.0798 A.data= 0.9202\n",
      "Ep 49: zero_grad(): A.grad= 0.0000 A.data= 0.9202 loss= 0.0032\n",
      "            step(): A.grad=-0.0798 A.data= 1.0718\n",
      "Ep 50: zero_grad(): A.grad= 0.0000 A.data= 1.0718 loss= 0.0026\n",
      "            step(): A.grad= 0.0718 A.data= 1.0718\n",
      "Ep 51: zero_grad(): A.grad= 0.0000 A.data= 1.0718 loss= 0.0026\n",
      "            step(): A.grad= 0.0718 A.data= 0.9354\n",
      "Ep 52: zero_grad(): A.grad= 0.0000 A.data= 0.9354 loss= 0.0021\n",
      "            step(): A.grad=-0.0646 A.data= 0.9354\n",
      "Ep 53: zero_grad(): A.grad= 0.0000 A.data= 0.9354 loss= 0.0021\n",
      "            step(): A.grad=-0.0646 A.data= 1.0581\n",
      "Ep 54: zero_grad(): A.grad= 0.0000 A.data= 1.0581 loss= 0.0017\n",
      "            step(): A.grad= 0.0581 A.data= 1.0581\n",
      "Ep 55: zero_grad(): A.grad= 0.0000 A.data= 1.0581 loss= 0.0017\n",
      "            step(): A.grad= 0.0581 A.data= 0.9477\n",
      "Ep 56: zero_grad(): A.grad= 0.0000 A.data= 0.9477 loss= 0.0014\n",
      "            step(): A.grad=-0.0523 A.data= 0.9477\n",
      "Ep 57: zero_grad(): A.grad= 0.0000 A.data= 0.9477 loss= 0.0014\n",
      "            step(): A.grad=-0.0523 A.data= 1.0471\n",
      "Ep 58: zero_grad(): A.grad= 0.0000 A.data= 1.0471 loss= 0.0011\n",
      "            step(): A.grad= 0.0471 A.data= 1.0471\n",
      "Ep 59: zero_grad(): A.grad= 0.0000 A.data= 1.0471 loss= 0.0011\n",
      "            step(): A.grad= 0.0471 A.data= 0.9576\n",
      "Ep 60: zero_grad(): A.grad= 0.0000 A.data= 0.9576 loss= 0.0009\n",
      "            step(): A.grad=-0.0424 A.data= 0.9576\n",
      "Ep 61: zero_grad(): A.grad= 0.0000 A.data= 0.9576 loss= 0.0009\n",
      "            step(): A.grad=-0.0424 A.data= 1.0382\n",
      "Ep 62: zero_grad(): A.grad= 0.0000 A.data= 1.0382 loss= 0.0007\n",
      "            step(): A.grad= 0.0382 A.data= 1.0382\n",
      "Ep 63: zero_grad(): A.grad= 0.0000 A.data= 1.0382 loss= 0.0007\n",
      "            step(): A.grad= 0.0382 A.data= 0.9657\n",
      "Ep 64: zero_grad(): A.grad= 0.0000 A.data= 0.9657 loss= 0.0006\n",
      "            step(): A.grad=-0.0343 A.data= 0.9657\n",
      "Ep 65: zero_grad(): A.grad= 0.0000 A.data= 0.9657 loss= 0.0006\n",
      "            step(): A.grad=-0.0343 A.data= 1.0309\n",
      "Ep 66: zero_grad(): A.grad= 0.0000 A.data= 1.0309 loss= 0.0005\n",
      "            step(): A.grad= 0.0309 A.data= 1.0309\n",
      "Ep 67: zero_grad(): A.grad= 0.0000 A.data= 1.0309 loss= 0.0005\n",
      "            step(): A.grad= 0.0309 A.data= 0.9722\n",
      "Ep 68: zero_grad(): A.grad= 0.0000 A.data= 0.9722 loss= 0.0004\n",
      "            step(): A.grad=-0.0278 A.data= 0.9722\n",
      "Ep 69: zero_grad(): A.grad= 0.0000 A.data= 0.9722 loss= 0.0004\n",
      "            step(): A.grad=-0.0278 A.data= 1.0250\n",
      "Ep 70: zero_grad(): A.grad= 0.0000 A.data= 1.0250 loss= 0.0003\n",
      "            step(): A.grad= 0.0250 A.data= 1.0250\n",
      "Ep 71: zero_grad(): A.grad= 0.0000 A.data= 1.0250 loss= 0.0003\n",
      "            step(): A.grad= 0.0250 A.data= 0.9775\n",
      "Ep 72: zero_grad(): A.grad= 0.0000 A.data= 0.9775 loss= 0.0003\n",
      "            step(): A.grad=-0.0225 A.data= 0.9775\n",
      "Ep 73: zero_grad(): A.grad= 0.0000 A.data= 0.9775 loss= 0.0003\n",
      "            step(): A.grad=-0.0225 A.data= 1.0203\n",
      "Ep 74: zero_grad(): A.grad= 0.0000 A.data= 1.0203 loss= 0.0002\n",
      "            step(): A.grad= 0.0203 A.data= 1.0203\n",
      "Ep 75: zero_grad(): A.grad= 0.0000 A.data= 1.0203 loss= 0.0002\n",
      "            step(): A.grad= 0.0203 A.data= 0.9818\n",
      "Ep 76: zero_grad(): A.grad= 0.0000 A.data= 0.9818 loss= 0.0002\n",
      "            step(): A.grad=-0.0182 A.data= 0.9818\n",
      "Ep 77: zero_grad(): A.grad= 0.0000 A.data= 0.9818 loss= 0.0002\n",
      "            step(): A.grad=-0.0182 A.data= 1.0164\n",
      "Ep 78: zero_grad(): A.grad= 0.0000 A.data= 1.0164 loss= 0.0001\n",
      "            step(): A.grad= 0.0164 A.data= 1.0164\n",
      "Ep 79: zero_grad(): A.grad= 0.0000 A.data= 1.0164 loss= 0.0001\n",
      "            step(): A.grad= 0.0164 A.data= 0.9852\n",
      "Ep 80: zero_grad(): A.grad= 0.0000 A.data= 0.9852 loss= 0.0001\n",
      "            step(): A.grad=-0.0148 A.data= 0.9852\n",
      "Ep 81: zero_grad(): A.grad= 0.0000 A.data= 0.9852 loss= 0.0001\n",
      "            step(): A.grad=-0.0148 A.data= 1.0133\n",
      "Ep 82: zero_grad(): A.grad= 0.0000 A.data= 1.0133 loss= 0.0001\n",
      "            step(): A.grad= 0.0133 A.data= 1.0133\n",
      "Ep 83: zero_grad(): A.grad= 0.0000 A.data= 1.0133 loss= 0.0001\n",
      "            step(): A.grad= 0.0133 A.data= 0.9880\n",
      "Ep 84: zero_grad(): A.grad= 0.0000 A.data= 0.9880 loss= 0.0001\n",
      "            step(): A.grad=-0.0120 A.data= 0.9880\n",
      "Ep 85: zero_grad(): A.grad= 0.0000 A.data= 0.9880 loss= 0.0001\n",
      "            step(): A.grad=-0.0120 A.data= 1.0108\n",
      "Ep 86: zero_grad(): A.grad= 0.0000 A.data= 1.0108 loss= 0.0001\n",
      "            step(): A.grad= 0.0108 A.data= 1.0108\n",
      "Ep 87: zero_grad(): A.grad= 0.0000 A.data= 1.0108 loss= 0.0001\n",
      "            step(): A.grad= 0.0108 A.data= 0.9903\n",
      "Ep 88: zero_grad(): A.grad= 0.0000 A.data= 0.9903 loss= 0.0000\n",
      "            step(): A.grad=-0.0097 A.data= 0.9903\n",
      "Ep 89: zero_grad(): A.grad= 0.0000 A.data= 0.9903 loss= 0.0000\n",
      "            step(): A.grad=-0.0097 A.data= 1.0087\n",
      "Ep 90: zero_grad(): A.grad= 0.0000 A.data= 1.0087 loss= 0.0000\n",
      "            step(): A.grad= 0.0087 A.data= 1.0087\n",
      "Ep 91: zero_grad(): A.grad= 0.0000 A.data= 1.0087 loss= 0.0000\n",
      "            step(): A.grad= 0.0087 A.data= 0.9921\n",
      "Ep 92: zero_grad(): A.grad= 0.0000 A.data= 0.9921 loss= 0.0000\n",
      "            step(): A.grad=-0.0079 A.data= 0.9921\n",
      "Ep 93: zero_grad(): A.grad= 0.0000 A.data= 0.9921 loss= 0.0000\n",
      "            step(): A.grad=-0.0079 A.data= 1.0071\n",
      "Ep 94: zero_grad(): A.grad= 0.0000 A.data= 1.0071 loss= 0.0000\n",
      "            step(): A.grad= 0.0071 A.data= 1.0071\n",
      "Ep 95: zero_grad(): A.grad= 0.0000 A.data= 1.0071 loss= 0.0000\n",
      "            step(): A.grad= 0.0071 A.data= 0.9936\n",
      "Ep 96: zero_grad(): A.grad= 0.0000 A.data= 0.9936 loss= 0.0000\n",
      "            step(): A.grad=-0.0064 A.data= 0.9936\n",
      "Ep 97: zero_grad(): A.grad= 0.0000 A.data= 0.9936 loss= 0.0000\n",
      "            step(): A.grad=-0.0064 A.data= 1.0057\n",
      "Ep 98: zero_grad(): A.grad= 0.0000 A.data= 1.0057 loss= 0.0000\n",
      "            step(): A.grad= 0.0057 A.data= 1.0057\n",
      "Ep 99: zero_grad(): A.grad= 0.0000 A.data= 1.0057 loss= 0.0000\n",
      "            step(): A.grad= 0.0057 A.data= 0.9948\n",
      "Ep100: zero_grad(): A.grad= 0.0000 A.data= 0.9948 loss= 0.0000\n",
      "            step(): A.grad=-0.0052 A.data= 0.9948\n",
      "Ep101: zero_grad(): A.grad= 0.0000 A.data= 0.9948 loss= 0.0000\n",
      "            step(): A.grad=-0.0052 A.data= 1.0046\n",
      "Ep102: zero_grad(): A.grad= 0.0000 A.data= 1.0046 loss= 0.0000\n",
      "            step(): A.grad= 0.0046 A.data= 1.0046\n",
      "Ep103: zero_grad(): A.grad= 0.0000 A.data= 1.0046 loss= 0.0000\n",
      "            step(): A.grad= 0.0046 A.data= 0.9958\n",
      "Ep104: zero_grad(): A.grad= 0.0000 A.data= 0.9958 loss= 0.0000\n",
      "            step(): A.grad=-0.0042 A.data= 0.9958\n",
      "Ep105: zero_grad(): A.grad= 0.0000 A.data= 0.9958 loss= 0.0000\n",
      "            step(): A.grad=-0.0042 A.data= 1.0038\n",
      "Ep106: zero_grad(): A.grad= 0.0000 A.data= 1.0038 loss= 0.0000\n",
      "            step(): A.grad= 0.0038 A.data= 1.0038\n",
      "Ep107: zero_grad(): A.grad= 0.0000 A.data= 1.0038 loss= 0.0000\n",
      "            step(): A.grad= 0.0038 A.data= 0.9966\n",
      "Ep108: zero_grad(): A.grad= 0.0000 A.data= 0.9966 loss= 0.0000\n",
      "            step(): A.grad=-0.0034 A.data= 0.9966\n",
      "Ep109: zero_grad(): A.grad= 0.0000 A.data= 0.9966 loss= 0.0000\n",
      "            step(): A.grad=-0.0034 A.data= 1.0030\n",
      "Ep110: zero_grad(): A.grad= 0.0000 A.data= 1.0030 loss= 0.0000\n",
      "            step(): A.grad= 0.0030 A.data= 1.0030\n",
      "Ep111: zero_grad(): A.grad= 0.0000 A.data= 1.0030 loss= 0.0000\n",
      "            step(): A.grad= 0.0030 A.data= 0.9973\n",
      "Ep112: zero_grad(): A.grad= 0.0000 A.data= 0.9973 loss= 0.0000\n",
      "            step(): A.grad=-0.0027 A.data= 0.9973\n",
      "Ep113: zero_grad(): A.grad= 0.0000 A.data= 0.9973 loss= 0.0000\n",
      "            step(): A.grad=-0.0027 A.data= 1.0025\n",
      "Ep114: zero_grad(): A.grad= 0.0000 A.data= 1.0025 loss= 0.0000\n",
      "            step(): A.grad= 0.0025 A.data= 1.0025\n",
      "Ep115: zero_grad(): A.grad= 0.0000 A.data= 1.0025 loss= 0.0000\n",
      "            step(): A.grad= 0.0025 A.data= 0.9978\n",
      "Ep116: zero_grad(): A.grad= 0.0000 A.data= 0.9978 loss= 0.0000\n",
      "            step(): A.grad=-0.0022 A.data= 0.9978\n",
      "Ep117: zero_grad(): A.grad= 0.0000 A.data= 0.9978 loss= 0.0000\n",
      "            step(): A.grad=-0.0022 A.data= 1.0020\n",
      "Ep118: zero_grad(): A.grad= 0.0000 A.data= 1.0020 loss= 0.0000\n",
      "            step(): A.grad= 0.0020 A.data= 1.0020\n",
      "Ep119: zero_grad(): A.grad= 0.0000 A.data= 1.0020 loss= 0.0000\n",
      "            step(): A.grad= 0.0020 A.data= 0.9982\n",
      "Ep120: zero_grad(): A.grad= 0.0000 A.data= 0.9982 loss= 0.0000\n",
      "            step(): A.grad=-0.0018 A.data= 0.9982\n",
      "Ep121: zero_grad(): A.grad= 0.0000 A.data= 0.9982 loss= 0.0000\n",
      "            step(): A.grad=-0.0018 A.data= 1.0016\n",
      "Ep122: zero_grad(): A.grad= 0.0000 A.data= 1.0016 loss= 0.0000\n",
      "            step(): A.grad= 0.0016 A.data= 1.0016\n",
      "Ep123: zero_grad(): A.grad= 0.0000 A.data= 1.0016 loss= 0.0000\n",
      "            step(): A.grad= 0.0016 A.data= 0.9985\n",
      "Ep124: zero_grad(): A.grad= 0.0000 A.data= 0.9985 loss= 0.0000\n",
      "            step(): A.grad=-0.0015 A.data= 0.9985\n",
      "Ep125: zero_grad(): A.grad= 0.0000 A.data= 0.9985 loss= 0.0000\n",
      "            step(): A.grad=-0.0015 A.data= 1.0013\n",
      "Ep126: zero_grad(): A.grad= 0.0000 A.data= 1.0013 loss= 0.0000\n",
      "            step(): A.grad= 0.0013 A.data= 1.0013\n",
      "Ep127: zero_grad(): A.grad= 0.0000 A.data= 1.0013 loss= 0.0000\n",
      "            step(): A.grad= 0.0013 A.data= 0.9988\n",
      "Ep128: zero_grad(): A.grad= 0.0000 A.data= 0.9988 loss= 0.0000\n",
      "            step(): A.grad=-0.0012 A.data= 0.9988\n",
      "Ep129: zero_grad(): A.grad= 0.0000 A.data= 0.9988 loss= 0.0000\n",
      "            step(): A.grad=-0.0012 A.data= 1.0011\n",
      "Ep130: zero_grad(): A.grad= 0.0000 A.data= 1.0011 loss= 0.0000\n",
      "            step(): A.grad= 0.0011 A.data= 1.0011\n",
      "Ep131: zero_grad(): A.grad= 0.0000 A.data= 1.0011 loss= 0.0000\n",
      "            step(): A.grad= 0.0011 A.data= 0.9990\n",
      "Ep132: zero_grad(): A.grad= 0.0000 A.data= 0.9990 loss= 0.0000\n",
      "            step(): A.grad=-0.0010 A.data= 0.9990\n",
      "Ep133: zero_grad(): A.grad= 0.0000 A.data= 0.9990 loss= 0.0000\n",
      "            step(): A.grad=-0.0010 A.data= 1.0009\n",
      "Ep134: zero_grad(): A.grad= 0.0000 A.data= 1.0009 loss= 0.0000\n",
      "            step(): A.grad= 0.0009 A.data= 1.0009\n",
      "Ep135: zero_grad(): A.grad= 0.0000 A.data= 1.0009 loss= 0.0000\n",
      "            step(): A.grad= 0.0009 A.data= 0.9992\n",
      "Ep136: zero_grad(): A.grad= 0.0000 A.data= 0.9992 loss= 0.0000\n",
      "            step(): A.grad=-0.0008 A.data= 0.9992\n",
      "Ep137: zero_grad(): A.grad= 0.0000 A.data= 0.9992 loss= 0.0000\n",
      "            step(): A.grad=-0.0008 A.data= 1.0007\n",
      "Ep138: zero_grad(): A.grad= 0.0000 A.data= 1.0007 loss= 0.0000\n",
      "            step(): A.grad= 0.0007 A.data= 1.0007\n",
      "Ep139: zero_grad(): A.grad= 0.0000 A.data= 1.0007 loss= 0.0000\n",
      "            step(): A.grad= 0.0007 A.data= 0.9994\n",
      "Ep140: zero_grad(): A.grad= 0.0000 A.data= 0.9994 loss= 0.0000\n",
      "            step(): A.grad=-0.0006 A.data= 0.9994\n",
      "Ep141: zero_grad(): A.grad= 0.0000 A.data= 0.9994 loss= 0.0000\n",
      "            step(): A.grad=-0.0006 A.data= 1.0006\n",
      "Ep142: zero_grad(): A.grad= 0.0000 A.data= 1.0006 loss= 0.0000\n",
      "            step(): A.grad= 0.0006 A.data= 1.0006\n",
      "Ep143: zero_grad(): A.grad= 0.0000 A.data= 1.0006 loss= 0.0000\n",
      "            step(): A.grad= 0.0006 A.data= 0.9995\n",
      "Ep144: zero_grad(): A.grad= 0.0000 A.data= 0.9995 loss= 0.0000\n",
      "            step(): A.grad=-0.0005 A.data= 0.9995\n",
      "Ep145: zero_grad(): A.grad= 0.0000 A.data= 0.9995 loss= 0.0000\n",
      "            step(): A.grad=-0.0005 A.data= 1.0005\n",
      "Ep146: zero_grad(): A.grad= 0.0000 A.data= 1.0005 loss= 0.0000\n",
      "            step(): A.grad= 0.0005 A.data= 1.0005\n",
      "Ep147: zero_grad(): A.grad= 0.0000 A.data= 1.0005 loss= 0.0000\n",
      "            step(): A.grad= 0.0005 A.data= 0.9996\n",
      "Ep148: zero_grad(): A.grad= 0.0000 A.data= 0.9996 loss= 0.0000\n",
      "            step(): A.grad=-0.0004 A.data= 0.9996\n",
      "Ep149: zero_grad(): A.grad= 0.0000 A.data= 0.9996 loss= 0.0000\n",
      "            step(): A.grad=-0.0004 A.data= 1.0004\n",
      "Ep150: zero_grad(): A.grad= 0.0000 A.data= 1.0004 loss= 0.0000\n",
      "            step(): A.grad= 0.0004 A.data= 1.0004\n",
      "Ep151: zero_grad(): A.grad= 0.0000 A.data= 1.0004 loss= 0.0000\n",
      "            step(): A.grad= 0.0004 A.data= 0.9997\n",
      "Ep152: zero_grad(): A.grad= 0.0000 A.data= 0.9997 loss= 0.0000\n",
      "            step(): A.grad=-0.0003 A.data= 0.9997\n",
      "Ep153: zero_grad(): A.grad= 0.0000 A.data= 0.9997 loss= 0.0000\n",
      "            step(): A.grad=-0.0003 A.data= 1.0003\n",
      "Ep154: zero_grad(): A.grad= 0.0000 A.data= 1.0003 loss= 0.0000\n",
      "            step(): A.grad= 0.0003 A.data= 1.0003\n",
      "Ep155: zero_grad(): A.grad= 0.0000 A.data= 1.0003 loss= 0.0000\n",
      "            step(): A.grad= 0.0003 A.data= 0.9997\n",
      "Ep156: zero_grad(): A.grad= 0.0000 A.data= 0.9997 loss= 0.0000\n",
      "            step(): A.grad=-0.0003 A.data= 0.9997\n",
      "Ep157: zero_grad(): A.grad= 0.0000 A.data= 0.9997 loss= 0.0000\n",
      "            step(): A.grad=-0.0003 A.data= 1.0002\n",
      "Ep158: zero_grad(): A.grad= 0.0000 A.data= 1.0002 loss= 0.0000\n",
      "            step(): A.grad= 0.0002 A.data= 1.0002\n",
      "Ep159: zero_grad(): A.grad= 0.0000 A.data= 1.0002 loss= 0.0000\n",
      "            step(): A.grad= 0.0002 A.data= 0.9998\n",
      "Ep160: zero_grad(): A.grad= 0.0000 A.data= 0.9998 loss= 0.0000\n",
      "            step(): A.grad=-0.0002 A.data= 0.9998\n",
      "Ep161: zero_grad(): A.grad= 0.0000 A.data= 0.9998 loss= 0.0000\n",
      "            step(): A.grad=-0.0002 A.data= 1.0002\n",
      "Ep162: zero_grad(): A.grad= 0.0000 A.data= 1.0002 loss= 0.0000\n",
      "            step(): A.grad= 0.0002 A.data= 1.0002\n",
      "Ep163: zero_grad(): A.grad= 0.0000 A.data= 1.0002 loss= 0.0000\n",
      "            step(): A.grad= 0.0002 A.data= 0.9998\n",
      "Ep164: zero_grad(): A.grad= 0.0000 A.data= 0.9998 loss= 0.0000\n",
      "            step(): A.grad=-0.0002 A.data= 0.9998\n",
      "Ep165: zero_grad(): A.grad= 0.0000 A.data= 0.9998 loss= 0.0000\n",
      "            step(): A.grad=-0.0002 A.data= 1.0002\n",
      "Ep166: zero_grad(): A.grad= 0.0000 A.data= 1.0002 loss= 0.0000\n",
      "            step(): A.grad= 0.0002 A.data= 1.0002\n",
      "Ep167: zero_grad(): A.grad= 0.0000 A.data= 1.0002 loss= 0.0000\n",
      "            step(): A.grad= 0.0002 A.data= 0.9999\n",
      "Ep168: zero_grad(): A.grad= 0.0000 A.data= 0.9999 loss= 0.0000\n",
      "            step(): A.grad=-0.0001 A.data= 0.9999\n",
      "Ep169: zero_grad(): A.grad= 0.0000 A.data= 0.9999 loss= 0.0000\n",
      "            step(): A.grad=-0.0001 A.data= 1.0001\n",
      "Ep170: zero_grad(): A.grad= 0.0000 A.data= 1.0001 loss= 0.0000\n",
      "            step(): A.grad= 0.0001 A.data= 1.0001\n",
      "Ep171: zero_grad(): A.grad= 0.0000 A.data= 1.0001 loss= 0.0000\n",
      "            step(): A.grad= 0.0001 A.data= 0.9999\n",
      "Ep172: zero_grad(): A.grad= 0.0000 A.data= 0.9999 loss= 0.0000\n",
      "            step(): A.grad=-0.0001 A.data= 0.9999\n",
      "Ep173: zero_grad(): A.grad= 0.0000 A.data= 0.9999 loss= 0.0000\n",
      "            step(): A.grad=-0.0001 A.data= 1.0001\n",
      "Ep174: zero_grad(): A.grad= 0.0000 A.data= 1.0001 loss= 0.0000\n",
      "            step(): A.grad= 0.0001 A.data= 1.0001\n",
      "Ep175: zero_grad(): A.grad= 0.0000 A.data= 1.0001 loss= 0.0000\n",
      "            step(): A.grad= 0.0001 A.data= 0.9999\n",
      "Ep176: zero_grad(): A.grad= 0.0000 A.data= 0.9999 loss= 0.0000\n",
      "            step(): A.grad=-0.0001 A.data= 0.9999\n",
      "Ep177: zero_grad(): A.grad= 0.0000 A.data= 0.9999 loss= 0.0000\n",
      "            step(): A.grad=-0.0001 A.data= 1.0001\n",
      "Ep178: zero_grad(): A.grad= 0.0000 A.data= 1.0001 loss= 0.0000\n",
      "            step(): A.grad= 0.0001 A.data= 1.0001\n",
      "Ep179: zero_grad(): A.grad= 0.0000 A.data= 1.0001 loss= 0.0000\n",
      "            step(): A.grad= 0.0001 A.data= 0.9999\n",
      "Ep180: zero_grad(): A.grad= 0.0000 A.data= 0.9999 loss= 0.0000\n",
      "            step(): A.grad=-0.0001 A.data= 0.9999\n",
      "Ep181: zero_grad(): A.grad= 0.0000 A.data= 0.9999 loss= 0.0000\n",
      "            step(): A.grad=-0.0001 A.data= 1.0001\n",
      "Ep182: zero_grad(): A.grad= 0.0000 A.data= 1.0001 loss= 0.0000\n",
      "            step(): A.grad= 0.0001 A.data= 1.0001\n",
      "Ep183: zero_grad(): A.grad= 0.0000 A.data= 1.0001 loss= 0.0000\n",
      "            step(): A.grad= 0.0001 A.data= 0.9999\n",
      "Ep184: zero_grad(): A.grad= 0.0000 A.data= 0.9999 loss= 0.0000\n",
      "            step(): A.grad=-0.0001 A.data= 0.9999\n",
      "Ep185: zero_grad(): A.grad= 0.0000 A.data= 0.9999 loss= 0.0000\n",
      "            step(): A.grad=-0.0001 A.data= 1.0001\n",
      "Ep186: zero_grad(): A.grad= 0.0000 A.data= 1.0001 loss= 0.0000\n",
      "            step(): A.grad= 0.0001 A.data= 1.0001\n",
      "Ep187: zero_grad(): A.grad= 0.0000 A.data= 1.0001 loss= 0.0000\n",
      "            step(): A.grad= 0.0001 A.data= 0.9999\n",
      "Ep188: zero_grad(): A.grad= 0.0000 A.data= 0.9999 loss= 0.0000\n",
      "            step(): A.grad=-0.0001 A.data= 0.9999\n",
      "Ep189: zero_grad(): A.grad= 0.0000 A.data= 0.9999 loss= 0.0000\n",
      "            step(): A.grad=-0.0001 A.data= 1.0000\n",
      "Ep190: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep191: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep192: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep193: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep194: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep195: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep196: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep197: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep198: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep199: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep200: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep201: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep202: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep203: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep204: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep205: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep206: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep207: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep208: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep209: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep210: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep211: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep212: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep213: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep214: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep215: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep216: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep217: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep218: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep219: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep220: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep221: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep222: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep223: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep224: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep225: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep226: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep227: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep228: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep229: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep230: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep231: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep232: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep233: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep234: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep235: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep236: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep237: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep238: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep239: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep240: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep241: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep242: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep243: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep244: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep245: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep246: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep247: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep248: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep249: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep250: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep251: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep252: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep253: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep254: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep255: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep256: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep257: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep258: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep259: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep260: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep261: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep262: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep263: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep264: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep265: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep266: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep267: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep268: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep269: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep270: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep271: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep272: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep273: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep274: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep275: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep276: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep277: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep278: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep279: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep280: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep281: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep282: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep283: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep284: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep285: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep286: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep287: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep288: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep289: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep290: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep291: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep292: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep293: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep294: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep295: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep296: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep297: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep298: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep299: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep300: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep301: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep302: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep303: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep304: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep305: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep306: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep307: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep308: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep309: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep310: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep311: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep312: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad=-0.0000 A.data= 1.0000\n",
      "Ep313: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep314: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep315: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep316: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep317: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep318: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep319: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep320: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep321: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep322: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep323: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep324: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep325: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep326: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep327: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep328: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep329: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep330: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep331: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep332: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep333: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep334: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep335: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep336: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep337: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep338: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep339: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep340: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep341: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep342: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep343: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep344: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep345: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep346: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep347: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep348: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep349: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep350: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep351: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep352: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep353: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep354: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep355: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep356: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep357: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep358: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep359: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep360: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep361: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep362: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep363: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep364: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep365: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep366: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep367: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep368: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep369: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep370: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep371: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep372: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep373: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep374: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep375: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep376: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep377: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep378: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep379: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep380: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep381: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep382: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep383: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep384: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep385: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep386: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep387: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep388: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep389: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep390: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep391: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep392: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep393: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep394: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep395: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep396: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep397: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep398: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep399: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep400: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep401: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep402: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep403: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep404: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep405: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep406: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep407: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep408: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep409: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep410: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep411: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep412: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep413: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep414: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep415: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep416: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep417: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep418: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep419: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep420: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep421: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep422: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep423: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep424: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep425: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep426: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep427: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep428: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep429: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep430: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep431: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep432: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep433: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep434: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep435: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep436: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep437: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep438: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep439: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep440: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep441: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep442: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep443: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep444: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep445: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep446: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep447: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep448: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep449: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep450: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep451: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep452: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep453: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep454: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep455: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep456: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep457: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep458: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep459: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep460: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep461: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep462: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep463: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep464: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep465: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep466: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep467: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep468: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep469: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep470: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep471: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep472: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep473: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep474: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep475: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep476: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep477: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep478: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep479: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep480: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep481: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep482: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep483: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep484: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep485: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep486: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep487: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep488: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep489: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep490: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep491: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep492: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep493: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep494: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep495: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep496: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep497: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep498: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep499: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep500: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep501: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep502: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep503: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep504: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep505: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep506: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep507: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep508: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep509: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep510: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep511: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep512: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep513: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep514: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep515: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep516: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep517: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep518: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep519: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep520: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep521: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep522: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep523: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep524: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep525: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep526: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep527: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep528: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep529: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep530: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep531: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep532: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep533: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep534: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep535: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep536: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep537: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep538: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep539: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep540: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep541: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep542: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep543: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep544: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep545: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep546: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep547: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep548: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep549: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep550: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep551: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep552: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep553: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep554: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep555: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep556: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep557: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep558: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep559: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep560: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep561: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep562: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep563: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep564: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep565: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep566: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep567: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep568: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep569: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep570: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep571: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep572: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep573: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep574: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep575: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep576: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep577: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep578: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep579: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep580: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep581: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep582: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep583: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep584: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep585: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep586: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep587: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep588: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep589: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep590: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep591: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep592: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep593: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep594: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep595: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep596: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep597: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep598: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep599: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep600: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep601: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep602: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep603: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep604: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep605: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep606: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep607: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep608: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep609: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep610: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep611: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep612: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep613: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep614: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep615: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep616: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep617: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep618: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep619: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep620: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep621: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep622: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep623: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep624: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep625: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep626: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep627: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep628: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep629: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep630: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep631: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep632: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep633: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep634: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep635: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep636: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep637: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep638: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep639: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep640: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep641: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep642: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep643: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep644: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep645: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep646: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep647: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep648: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep649: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep650: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep651: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep652: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep653: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep654: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep655: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep656: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep657: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep658: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep659: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep660: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep661: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep662: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep663: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep664: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep665: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep666: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep667: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep668: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep669: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep670: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep671: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep672: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep673: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep674: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep675: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep676: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep677: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep678: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep679: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep680: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep681: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep682: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep683: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep684: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep685: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep686: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep687: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep688: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep689: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep690: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep691: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep692: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep693: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep694: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep695: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep696: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep697: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep698: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep699: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep700: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep701: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep702: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep703: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep704: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep705: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep706: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep707: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep708: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep709: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep710: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep711: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep712: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep713: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep714: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep715: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep716: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep717: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep718: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep719: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep720: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep721: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep722: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep723: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep724: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep725: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep726: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep727: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep728: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep729: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep730: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep731: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep732: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep733: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep734: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep735: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep736: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep737: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep738: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep739: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep740: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep741: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep742: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep743: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep744: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep745: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep746: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep747: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep748: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep749: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep750: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep751: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep752: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep753: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep754: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep755: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep756: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep757: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep758: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep759: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep760: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep761: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep762: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep763: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep764: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep765: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep766: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep767: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep768: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep769: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep770: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep771: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep772: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep773: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep774: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep775: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep776: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep777: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep778: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep779: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep780: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep781: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep782: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep783: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep784: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep785: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep786: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep787: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep788: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep789: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep790: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep791: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep792: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep793: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep794: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep795: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep796: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep797: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep798: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep799: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep800: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep801: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep802: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep803: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep804: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep805: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep806: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep807: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep808: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep809: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep810: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep811: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep812: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep813: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep814: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep815: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep816: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep817: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep818: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep819: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep820: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep821: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep822: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep823: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep824: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep825: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep826: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep827: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep828: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep829: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep830: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep831: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep832: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep833: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep834: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep835: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep836: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep837: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep838: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep839: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep840: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep841: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep842: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep843: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep844: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep845: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep846: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep847: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep848: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep849: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep850: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep851: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep852: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep853: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep854: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep855: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep856: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep857: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep858: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep859: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep860: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep861: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep862: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep863: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep864: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep865: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep866: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep867: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep868: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep869: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep870: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep871: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep872: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep873: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep874: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep875: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep876: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep877: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep878: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep879: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep880: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep881: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep882: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep883: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep884: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep885: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep886: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep887: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep888: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep889: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep890: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep891: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep892: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep893: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep894: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep895: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep896: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep897: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep898: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep899: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep900: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep901: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep902: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep903: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep904: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep905: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep906: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep907: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep908: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep909: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep910: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep911: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep912: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep913: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep914: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep915: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep916: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep917: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep918: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep919: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep920: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep921: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep922: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep923: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep924: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep925: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep926: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep927: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep928: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep929: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep930: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep931: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep932: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep933: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep934: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep935: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep936: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep937: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep938: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep939: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep940: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep941: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep942: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep943: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep944: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep945: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep946: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep947: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep948: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep949: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep950: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep951: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep952: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep953: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep954: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep955: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep956: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep957: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep958: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep959: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep960: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep961: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep962: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep963: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep964: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep965: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep966: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep967: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep968: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep969: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep970: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep971: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep972: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep973: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep974: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep975: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep976: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep977: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep978: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep979: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep980: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep981: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep982: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep983: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep984: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep985: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep986: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep987: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep988: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep989: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep990: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep991: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep992: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep993: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep994: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep995: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep996: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep997: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep998: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n",
      "Ep999: zero_grad(): A.grad= 0.0000 A.data= 1.0000 loss= 0.0000\n",
      "            step(): A.grad= 0.0000 A.data= 1.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "\n",
    "lr = 1.9  # learning rate\n",
    "mom = 0.9  # momentum\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.A = torch.nn.Parameter(torch.zeros(1, requires_grad=True))\n",
    "    def forward(self, input):\n",
    "        output  = self.A * input\n",
    "        return(output)\n",
    "\n",
    "input  = torch.Tensor([[1]])\n",
    "target = torch.Tensor([[1]])\n",
    "\n",
    "slope_dataset = torch.utils.data.TensorDataset(input, target)\n",
    "train_loader  = torch.utils.data.DataLoader(slope_dataset, batch_size=1)\n",
    "\n",
    "# create neural network according to model specification\n",
    "net = MyModel().to(device) # CPU or GPU\n",
    "\n",
    "# choose between SGD, Adam or other optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=mom)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "    for batch_id, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()  # zero the gradients\n",
    "        output = net(data)  # apply network\n",
    "        loss = 0.5*torch.mean((output-target) * (output-target))\n",
    "        if type(net.A.grad) == type(None):\n",
    "            print('Ep%3d: zero_grad(): A.grad=  None  A.data=%7.4f loss=%7.4f' \\\n",
    "                      % (epoch, net.A.data, loss))\n",
    "        else:\n",
    "            print('Ep%3d: zero_grad(): A.grad=%7.4f A.data=%7.4f loss=%7.4f' \\\n",
    "                      % (epoch, net.A.grad, net.A.data, loss))\n",
    "        loss.backward()  # compute gradients\n",
    "        optimizer.step()  # update weights\n",
    "        print('            step(): A.grad=%7.4f A.data=%7.4f' \\\n",
    "                      % (net.A.grad, net.A.data))\n",
    "        if loss < 0.000000001 or np.isnan(loss.data):\n",
    "            exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise: XOR with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep100: loss =  0.6725\n",
      "ep200: loss =  0.6182\n",
      "ep300: loss =  0.5233\n",
      "ep400: loss =  0.3734\n",
      "ep500: loss =  0.2390\n",
      "ep600: loss =  0.1604\n",
      "ep700: loss =  0.1163\n",
      "ep800: loss =  0.0896\n",
      "ep900: loss =  0.0722\n",
      "ep1000: loss =  0.0602\n",
      "ep1100: loss =  0.0514\n",
      "ep1200: loss =  0.0447\n",
      "ep1300: loss =  0.0396\n",
      "ep1400: loss =  0.0354\n",
      "ep1500: loss =  0.0320\n",
      "ep1600: loss =  0.0292\n",
      "ep1700: loss =  0.0268\n",
      "ep1800: loss =  0.0248\n",
      "ep1900: loss =  0.0230\n",
      "ep2000: loss =  0.0215\n",
      "ep2100: loss =  0.0202\n",
      "ep2200: loss =  0.0190\n",
      "ep2300: loss =  0.0179\n",
      "ep2400: loss =  0.0170\n",
      "ep2500: loss =  0.0161\n",
      "ep2600: loss =  0.0153\n",
      "ep2700: loss =  0.0146\n",
      "ep2800: loss =  0.0140\n",
      "ep2900: loss =  0.0134\n",
      "ep3000: loss =  0.0129\n",
      "ep3100: loss =  0.0124\n",
      "ep3200: loss =  0.0119\n",
      "ep3300: loss =  0.0115\n",
      "ep3400: loss =  0.0111\n",
      "ep3500: loss =  0.0107\n",
      "ep3600: loss =  0.0103\n",
      "ep3700: loss =  0.0100\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep3800: loss =  0.0097\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep3900: loss =  0.0094\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep4000: loss =  0.0091\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep4100: loss =  0.0089\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep4200: loss =  0.0086\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep4300: loss =  0.0084\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep4400: loss =  0.0082\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep4500: loss =  0.0080\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep4600: loss =  0.0078\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep4700: loss =  0.0076\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep4800: loss =  0.0074\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep4900: loss =  0.0072\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep5000: loss =  0.0071\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep5100: loss =  0.0069\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep5200: loss =  0.0068\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep5300: loss =  0.0066\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep5400: loss =  0.0065\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep5500: loss =  0.0063\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep5600: loss =  0.0062\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep5700: loss =  0.0061\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep5800: loss =  0.0060\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep5900: loss =  0.0059\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep6000: loss =  0.0058\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep6100: loss =  0.0057\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep6200: loss =  0.0056\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep6300: loss =  0.0055\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep6400: loss =  0.0054\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep6500: loss =  0.0053\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep6600: loss =  0.0052\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep6700: loss =  0.0051\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep6800: loss =  0.0050\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep6900: loss =  0.0049\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep7000: loss =  0.0049\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep7100: loss =  0.0048\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep7200: loss =  0.0047\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep7300: loss =  0.0046\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep7400: loss =  0.0046\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep7500: loss =  0.0045\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep7600: loss =  0.0044\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep7700: loss =  0.0044\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep7800: loss =  0.0043\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep7900: loss =  0.0043\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep8000: loss =  0.0042\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep8100: loss =  0.0041\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep8200: loss =  0.0041\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep8300: loss =  0.0040\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep8400: loss =  0.0040\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep8500: loss =  0.0039\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep8600: loss =  0.0039\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep8700: loss =  0.0038\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep8800: loss =  0.0038\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep8900: loss =  0.0037\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep9000: loss =  0.0037\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep9100: loss =  0.0036\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep9200: loss =  0.0036\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep9300: loss =  0.0036\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep9400: loss =  0.0035\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep9500: loss =  0.0035\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep9600: loss =  0.0034\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep9700: loss =  0.0034\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep9800: loss =  0.0034\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "ep9900: loss =  0.0033\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Global Mininum\n",
      "Local Minimum\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "lr = 0.1\n",
    "mom = 0.0\n",
    "init = 1.0\n",
    "\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # define structure of the network here\n",
    "        self.in_hid  = torch.nn.Linear(2,2)\n",
    "        self.hid_out = torch.nn.Linear(2,1)\n",
    "    def forward(self, input):\n",
    "        # apply network and return output\n",
    "        hid_sum = self.in_hid(input)\n",
    "        hidden  = torch.tanh(hid_sum)\n",
    "        out_sum = self.hid_out(hidden)\n",
    "        output  = torch.sigmoid(out_sum)\n",
    "        return(output)\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "input  = torch.Tensor([[0,0],[0,1],[1,0],[1,1]])\n",
    "target = torch.Tensor([[0],[1],[1],[0]])\n",
    "\n",
    "xor_dataset  = torch.utils.data.TensorDataset(input,target)\n",
    "train_loader = torch.utils.data.DataLoader(xor_dataset,batch_size=4)\n",
    "\n",
    "# create neural network according to model specification\n",
    "net = MyModel().to(device) # CPU or GPU\n",
    "\n",
    "# initialize weight values\n",
    "net.in_hid.weight.data.normal_(0,init)\n",
    "net.hid_out.weight.data.normal_(0,init)\n",
    "\n",
    "# choose between SGD, Adam or other optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=lr,momentum=mom)\n",
    "\n",
    "epochs = 10000\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "    #train(net, device, train_loader, optimizer)\n",
    "    for batch_id, (data,target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad() # zero the gradients\n",
    "        output = net(data)    # apply network\n",
    "        loss = F.binary_cross_entropy(output,target)\n",
    "        loss.backward()       # compute gradients\n",
    "        optimizer.step()      # update weights\n",
    "        if epoch % 100 == 0:\n",
    "            print('ep%3d: loss = %7.4f' % (epoch, loss.item()))\n",
    "        if loss < 0.01:\n",
    "            print(\"Global Mininum\")\n",
    "            exit(0)\n",
    "print(\"Local Minimum\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
