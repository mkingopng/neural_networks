{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eXmh8JAYNLXj",
        "oIC9wMv0OIj6"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMEa86dzfIfI"
      },
      "source": [
        "#Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lr_mLYdfL9j"
      },
      "source": [
        "Hi, and welcome to this notebook tutorial, where we'll build a really, really good model for the KMNIST dataset using the [fastai](https://www.fast.ai/about/) library and [wandb](https://www.wandb.com/) visualization tools. If you haven't already, you should definetly check out the main article that this notebook is based on, which discusses all the techniques used here in detail.\n",
        "\n",
        "I'll be taking through the code one step at time, and this entire notebook can be run end to end. So what are you waiting for? Run the cell below, and let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "butlaGWTVulE"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA2s9JQSVxzt"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJpTDh8-WJ3Y"
      },
      "source": [
        "The first thing we need to do is download wandb into our notebook instance. Wandb is a really powerful deep learning library that alllows us to monitor, visualize, and analyze our model's training progress without looking at weird numbers and hard-to-interpret graphs.\n",
        "\n",
        "For the code to work properly, you're going to need a wandb account (it's free! you can sign up [here](https://app.wandb.ai/login?signup=true)) from which you'll need to create an API key to enter below. However, unlike most other lengthy API key creating processes, all you have to do here is follow the link that pops up. It should take you to a site that looks that this:\n",
        "\n",
        "[IMAGE]\n",
        "\n",
        "From there, copy the API key and paste it into the prompt that shows up when you run the below cell. And you're done. The wandb link is now set up, and you're good to go!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oICWxBO2PrkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f662f8d5-333d-40ed-b3c3-7104d231d124"
      },
      "source": [
        "! pip install wandb\n",
        "! wandb login"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.3-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 3.2 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 56.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 60.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 53.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 65.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 65.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 57.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 54.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 72.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 72.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=e0256dcd6f1ce43a24c080634d8d098720c1a030ba0aba3134a31baf1226ebba\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UcqahQ7ijU_"
      },
      "source": [
        "Another quick thing we need to do is import all the python libraries required for this tutorial. Like, I mentioned, we're giong to use fastai and wandb."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jugRuzSTpEYm"
      },
      "source": [
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "from torch.utils.data import Dataset\n",
        "import wandb\n",
        "from fastai.callback.wandb import *\n",
        "from fastai.vision.data import ImageDataLoaders\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HldZmhLZV4qg"
      },
      "source": [
        "There's another little step we have to do to get wandb to work with our model, and that's to initialize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUrBsq2Bn2iw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "514cdea9-8d95-452e-da88-1da1a388f6fc"
      },
      "source": [
        "wandb.init()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmichael_kingston\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220917_232225-eahw5una</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/michael_kingston/uncategorized/runs/eahw5una\" target=\"_blank\">comic-lake-1</a></strong> to <a href=\"https://wandb.ai/michael_kingston/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/michael_kingston/uncategorized/runs/eahw5una?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f9cd3422050>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2arg2AQYoBpT"
      },
      "source": [
        "Since we're using the KMNIST dataset here, let's go ahead and clone the official repo for it. Note: this will not actually download the dataset. Instead, it'll provide a few helpful functions that'll help us dowload whatever we need when we need it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt0-r9KuV33N",
        "outputId": "a618185e-a3c6-4caa-dee0-340847e3b8e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! git clone https://github.com/rois-codh/kmnist.git\n",
        "import os\n",
        "os.chdir('kmnist')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'kmnist'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 211 (delta 0), reused 2 (delta 0), pack-reused 208\u001b[K\n",
            "Receiving objects: 100% (211/211), 408.64 KiB | 8.51 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcejFpI2OQlN"
      },
      "source": [
        "#Kuzushiji-MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ylXVJINoonx"
      },
      "source": [
        "The first dataset we're going to try out is KMNIST. This is a drop-in replacement for the original MNIST, with the same 10 classes and 70k images, but is harder to actually solve since it contains hard-to-read Japanese characters.\n",
        "\n",
        "Of, we need to have the actual dataset before training a model on it. So let's download it straight to the notebook instance. The function below will start an interative download interface, where you'll have to select the dataset and format you want. We'll be using KMNIST in numpy format so choose those optons.\n",
        "\n",
        "Select option 1 (KNIST) and then option 2 (NumPy format)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_GTrEEaN-Up",
        "outputId": "958ff653-7f06-45ae-8c90-b84d523b03f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! python download_data.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select a download option:\n",
            "1) Kuzushiji-MNIST (10 classes, 28x28, 70k examples)\n",
            "2) Kuzushiji-49 (49 classes, 28x28, 270k examples)\n",
            "3) Kuzushiji-Kanji (3832 classes, 64x64, 140k examples)\n",
            "> 1\n",
            "Please select a download option:\n",
            "1) MNIST data format (ubyte.gz)\n",
            "2) NumPy data format (.npz)\n",
            "> 2\n",
            "Downloading kmnist-train-imgs.npz - 18.0 MB\n",
            "100% 17954/17954 [00:30<00:00, 581.32KB/s] \n",
            "Downloading kmnist-train-labels.npz - 0.0 MB\n",
            "100% 30/30 [00:00<00:00, 182.96KB/s]\n",
            "Downloading kmnist-test-imgs.npz - 3.0 MB\n",
            "100% 3008/3008 [00:03<00:00, 918.35KB/s] \n",
            "Downloading kmnist-test-labels.npz - 0.0 MB\n",
            "100% 6/6 [00:00<00:00, 19538.68KB/s]\n",
            "All dataset files downloaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01KyY5HGpxER"
      },
      "source": [
        "Now that we have the entire dataset stored as numpy arrays, it should be fairly easy to work with. But there are two problem we need to work around.\n",
        "\n",
        "The first problem is that the KMNIST dataset stores images in a single channel (since all images are grayscale). So we need to do some quick preprocessing to transform them into the more standard 3 channel RGB format so that they work with models pretrained on ImageNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtL4MoEAt-dd"
      },
      "source": [
        "train_imgs = np.load('kmnist-train-imgs.npz')['arr_0']  #.reshape((232365, 1, 28, 28))\n",
        "train_labels = np.int64(np.load('kmnist-train-labels.npz')['arr_0'])\n",
        "\n",
        "train_imgs = np.expand_dims(train_imgs,axis=1)\n",
        "train_imgs = np.float32(np.repeat(train_imgs, 3, axis=1))\n",
        "\n",
        "test_imgs = np.load('kmnist-test-imgs.npz')['arr_0']  #.reshape((38547, 1, 28, 28))\n",
        "test_labels = np.int64(np.load('kmnist-test-labels.npz')['arr_0'])\n",
        "\n",
        "test_imgs = np.expand_dims(test_imgs,axis=1)\n",
        "test_imgs = np.float32(np.repeat(test_imgs, 3, axis=1))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4oq_qEJqlLg"
      },
      "source": [
        "The next issue is that fastai doesn't support numpy array images out of the box. So we need to create a new PyTorch dataset class which we can then wrap in a fastai databunch.\n",
        "\n",
        "If you're not familiar with fastai or PyTorch, don't worry too much about what's going on here. You won't have to do this in most cases since you'll probably have regular images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIx6BbJsJVQ8"
      },
      "source": [
        "class NumpyArrayDataset(Dataset):\n",
        "  \n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.c = np.unique(y).size # binary label\n",
        "        self.classes = [\"お\", \"き\", \"す\", \"つ\", \"な\", \"は\", \"ま\", \"や\", \"れ\", \"を\"] \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return self.x[i], self.y[i]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB7tRt6qrsYK"
      },
      "source": [
        "After setting up the `NumPyArrayDataset` class, we'll now create our DataBunch, which is a fastai object that wraps a PyTorch training dataset, a PyToch validation dataset, and also assigns a batch size. Overall, a DataBunch will make it much easier for our model to interact with the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCsu8OAaLIX7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "5203ebd1-c96c-48ea-ab66-620b37d20e80"
      },
      "source": [
        "train_ds = NumpyArrayDataset(train_imgs, train_labels)\n",
        "valid_ds = NumpyArrayDataset(test_imgs, test_labels)\n",
        "\n",
        "data = ImageDataLoaders.from_folder(train_ds, valid_ds, bs=128)\n",
        "data.normalize(imagenet_stats)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1a228eca1b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvalid_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNumpyArrayDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataLoaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagenet_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/vision/data.py\u001b[0m in \u001b[0;36mfrom_folder\u001b[0;34m(cls, path, train, valid, valid_pct, seed, vocab, item_tfms, batch_tfms, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m                            \u001b[0mitem_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem_tfms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                            batch_tfms=batch_tfms)\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/data/core.py\u001b[0m in \u001b[0;36mfrom_dblock\u001b[0;34m(cls, dblock, source, path, bs, val_bs, shuffle, device, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     ):\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_bs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     _docs=dict(__getitem__=\"Retrieve `DataLoader` at `i` (`0` is training, `1` is validation)\",\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/data/block.py\u001b[0m in \u001b[0;36mdataloaders\u001b[0;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     ) -> DataLoaders:\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mdsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'verbose'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafter_item\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_tfms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafter_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_tfms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/data/block.py\u001b[0m in \u001b[0;36mdatasets\u001b[0;34m(self, source, verbose)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> Datasets:\n\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m                     \u001b[0;34m;\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Collecting items from {source}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_items\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found {len(items)} items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitter\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mRandomSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mpv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{len(splits)} datasets of sizes {','.join([str(len(s)) for s in splits])}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/data/transforms.py\u001b[0m in \u001b[0;36mget_image_files\u001b[0;34m(path, recurse, folders)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_image_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;34m\"Get image files in `path` recursively, only in `folders`, if specified.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_extensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# %% ../nbs/05_data.transforms.ipynb 23\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/data/transforms.py\u001b[0m in \u001b[0;36mget_files\u001b[0;34m(path, extensions, recurse, folders, followlinks)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;34m\"Get all the files in `path` with optional `extensions`, optionally with `recurse`, only in `folders`, if specified.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mfolders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mextensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindowsPath\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mPosixPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             raise NotImplementedError(\"cannot instantiate %r on your system\"\n",
            "\u001b[0;32m/usr/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36m_from_parts\u001b[0;34m(cls, args, init)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;31m# right flavour.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36m_parse_args\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0mparts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                     \u001b[0;31m# Force-cast str subclasses to str (issue #21127)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NumpyArrayDataset"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DsgT0PC1IvN"
      },
      "source": [
        "If you want to submit your entry to the [official wandb KMNIST benchmark](https://app.wandb.ai/wandb/kmnist/benchmark), you have to rename the default accuray metric to `kmnist_val_acc`. They compute the same thing, just with different names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYu8U1KTyusH"
      },
      "source": [
        "def kmnist_val_acc(): metrics.accuracy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Tzng70GwkoB"
      },
      "source": [
        "Now we're starting the fun stuff! In fastai, it's really easy to create a model and get started. Here, I'm going to create a 34 layer ResNet that's pretrained on ImageNet. In my experiments, this seemed to strike a good balance between training speed and accuracy. But feel free to try out any other architecture you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfweHIxkH3YT",
        "outputId": "6b1451d1-f14a-4dc4-db9c-7db459297351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "learn = cnn_learner(data, models.resnet34, metrics=accuracy)\n",
        "learn.loss_func = torch.nn.functional.cross_entropy\n",
        "learn.unfreeze()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n",
            "100%|██████████| 87306240/87306240 [00:00<00:00, 90812531.83it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED1MKa3o2Rr8"
      },
      "source": [
        "If you've read the main article (which you should have), you'll know what an important part the learning rate finder plays. Luckily, fastai makes it really easy to implent this in just 2 lines of code! There more details on what exactly we're doing here and why it works in the article, so finish reading it to get a clearer picture of the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a7iheu_f5R-",
        "outputId": "9281d4c1-2e6d-4ef9-e41e-a9528ad648c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nR2kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzL7Qg5K3ndq"
      },
      "source": [
        "Finally, we'll fit the model to our data, using the optimal learning rate of `1e-2` which we found using the plot above (the optimal learning rate is the one that produces the steepest slope in loss).\n",
        "\n",
        "The wandb magic here is what helps keep us montor training. The coolest part is that your training statistics are uploaded to the eandb clous service in real time, so you keep this notebook running and watch how your model performs from [app.wandb.ai](https://app.wandb.ai).\n",
        "\n",
        "If all goes well, your model should achive around 97% accuracy, which is pretty good!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llmn_9wyrRPJ",
        "outputId": "4bc42d2e-10a1-4634-b410-e52fbb83aa1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "%%wandb\n",
        "learn.fit_one_cycle(10, max_lr=1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.332265</td>\n",
              "      <td>0.569788</td>\n",
              "      <td>0.825800</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.181026</td>\n",
              "      <td>0.423954</td>\n",
              "      <td>0.881700</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.165461</td>\n",
              "      <td>0.389219</td>\n",
              "      <td>0.879100</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.130766</td>\n",
              "      <td>0.313490</td>\n",
              "      <td>0.908800</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.098722</td>\n",
              "      <td>0.255301</td>\n",
              "      <td>0.932900</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.085785</td>\n",
              "      <td>0.189655</td>\n",
              "      <td>0.946800</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.059579</td>\n",
              "      <td>0.166035</td>\n",
              "      <td>0.955200</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.036171</td>\n",
              "      <td>0.145391</td>\n",
              "      <td>0.962100</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.034838</td>\n",
              "      <td>0.135079</td>\n",
              "      <td>0.966600</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.021453</td>\n",
              "      <td>0.135671</td>\n",
              "      <td>0.967800</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXmh8JAYNLXj"
      },
      "source": [
        "#Kuzushiji-49"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EA8srmw7T-1"
      },
      "source": [
        "Another, more complex variant of the KMNIST dataset is K-49, which as you could probaly tell from the name, has 49 possible classes. The method we use however, is pretty much the same.\n",
        "\n",
        "Using the code for KMNIST above as a refernce, see if you can modify the code here to create an accurate model for K-49. In particular, I've left the `max_lr` argument on the `fit_one_cycle` function blank. Try using your understanding of the learning rate finder to fill it in and train the model.\n",
        "\n",
        "One thing to note: K-49 has over 200k images, so your model might take much longer to train. But if you're patient enough, it should be possible to cross 80% accuracy using just this colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LojJyjuPNQi8"
      },
      "source": [
        "! python download_data.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WTxOC4ENRXG"
      },
      "source": [
        "train_imgs = np.load('k49-train-imgs.npz')['arr_0']#.reshape((232365, 1, 28, 28))\n",
        "train_labels = np.int64(np.load('k49-train-labels.npz')['arr_0'])\n",
        "\n",
        "train_imgs = np.expand_dims(train_imgs,axis=1)\n",
        "train_imgs = np.float32(np.repeat(train_imgs, 3, axis=1))\n",
        "#train_imgs = (train_imgs-train_imgs.mean()) / train_imgs.std()\n",
        "\n",
        "test_imgs = np.load('k49-test-imgs.npz')['arr_0']#.reshape((38547, 1, 28, 28))\n",
        "test_labels = np.int64(np.load('k49-test-labels.npz')['arr_0'])\n",
        "\n",
        "test_imgs = np.expand_dims(test_imgs,axis=1)\n",
        "test_imgs = np.float32(np.repeat(test_imgs, 3, axis=1))\n",
        "#test_imgs = (test_imgs-test_imgs.mean()) / test_imgs.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKATgPLvNXyp"
      },
      "source": [
        "class NumpyArrayDataset(Dataset):\n",
        "  \n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.c = np.unique(y).size\n",
        "        self.classes = [\"お\", \"き\", \"す\", \"つ\", \"な\", \"は\", \"ま\", \"や\", \"れ\", \"を\"] \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return self.x[i], self.y[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXM-kD5kNb4m"
      },
      "source": [
        "train_ds = NumpyArrayDataset(train_imgs, train_labels)\n",
        "valid_ds = NumpyArrayDataset(test_imgs, test_labels)\n",
        "\n",
        "data = ImageDataBunch.create(train_ds, valid_ds, bs=128)\n",
        "data.normalize(imagenet_stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksGexlFMNd1h"
      },
      "source": [
        "learn = cnn_learner(data, models.resnet34, metrics=accuracy, callback_fns=WandbCallback)\n",
        "learn.loss_func = torch.nn.functional.cross_entropy\n",
        "learn.unfreeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oDPWzTpNgJh"
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpfaeYsPVz95"
      },
      "source": [
        "learn.fit_one_cycle(10, max_lr=____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIC9wMv0OIj6"
      },
      "source": [
        "#Kuzushiji-Kanji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tCzyPoi6Tdt"
      },
      "source": [
        "The largest dataset of the three Japanese character datasets is the Kuzusshiji-Kanji dataset, which contains over 3000 classes and 100k images that have a 64x64 resolution.\n",
        "\n",
        "The massive size of this dataset can make training extremely slow, so I'd reccomend you try it out in a faster V100 cloud instance via something like AWS or FloydHub.\n",
        "\n",
        "But in a way, Kuzushiji-Kanji can be easier to work with, since the files are served as regular images. Play around with the below code yourself and see if you can get any interesting results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLND6qHROPYf"
      },
      "source": [
        "! python download_data.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0KbNbaROp8h"
      },
      "source": [
        "import tarfile\n",
        "tar = tarfile.open(\"kkanji.tar\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIsw6Na8VN6a"
      },
      "source": [
        "data = ImageDataBunch.from_folder('kkanji2', valid_pct=0.2, bs = 1024)\n",
        "data.normalize(imagenet_stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFpLHpCVS6PF"
      },
      "source": [
        "learn = cnn_learner(data, models.resnet50, metrics=(accuracy,top_k_accuracy), callback_fns=WandbCallback)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqEoSHpkWjE5"
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-jPOxyL2lt-"
      },
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2jIFR8oXGJS"
      },
      "source": [
        "%%wandb\n",
        "learn.fit_one_cycle(10, max_lr=slice(3e-3,3e-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsT3JJf_cdAn"
      },
      "source": [
        "learn.validate(metrics=(accuracy,top_k_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn7OBaRF4m3B"
      },
      "source": [
        "#Conlusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p81p5fc4pm7"
      },
      "source": [
        "In this notebook, we trained a ResNet on the KMNIST Japanese characters dataset and got an accuracy of around 97%. If you completed that part, I'd reccomend you also try out the K-49 and Kuzushiji-Kanji datasets, for which we can use similar methods.\n",
        "\n",
        "The other two datasets, however, are more complicated, so your model will take longer to train, and your accracy might not be as good as it was for KMNIST. But deep learning is all about experimentation, so keep trying different model architectures, hyperparametrs, and training metods; you might just set a new state-of-the-art result!\n",
        "\n",
        "I hoped you enjoyed this tutorial, and learned a few things about how to effectively train neural nets not just for KMNIST, but any image dataset that you might use. If you want to learn more, definetly check out the article that's tied to this notebook, where I explain how the methods we use here work.\n",
        "\n",
        "Till then, see ya!"
      ]
    }
  ]
}